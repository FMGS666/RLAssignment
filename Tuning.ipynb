{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import gymnasium as gym\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import text_flappy_bird_gym\n",
    "\n",
    "from plotting.plotting import plot_value_function\n",
    "from Agents.TemporalDifferenceAgent import TemporalDifferenceAgent\n",
    "from Agents.ExpectedSarsa import ExpectedSarsa\n",
    "\n",
    "from __future__ import annotations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining Environment to Train Agents with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = 15\n",
    "width = 20 \n",
    "pipe_gap = 4\n",
    "env = gym.make(\n",
    "    'TextFlappyBird-v0', \n",
    "    height = height, \n",
    "    width = width, \n",
    "    pipe_gap = pipe_gap\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining Search Grids for TemporalDifferenceAgent(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters to tune:\n",
    "\n",
    "* Epsilon\n",
    "* Gamma\n",
    "* Alpha\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TDAgent_maxScore49_w20_h15_nAct2_eps0.1_nSteps1_gamma1_alpha0.001\n",
    "\n",
    "\n",
    "epsilon_grid = [\n",
    "    1e-1,\n",
    "    1e-2, \n",
    "    1e-3,\n",
    "    2e-2,\n",
    "    2e-2, \n",
    "    2e-3, \n",
    "]\n",
    "gamma_grid = [\n",
    "    1, \n",
    "    75e-2, \n",
    "    5e-1,\n",
    "]\n",
    "alpha_grid = [\n",
    "    1, \n",
    "    5e-1, \n",
    "    1e-1, \n",
    "    5e-2, \n",
    "    1e-2, \n",
    "    5e-3, \n",
    "    1e-3\n",
    "]\n",
    "n_steps_grid = [\n",
    "    1\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining Number of Episodes for each search, Patience for the search and Random Seed  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATIENCE = int(1e+3)\n",
    "N_EPISODES = int(5e+5)\n",
    "SEED = 1024"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Constructing Grid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "agents = []\n",
    "for epsilon in epsilon_grid:\n",
    "    for gamma in gamma_grid:\n",
    "        for alpha in alpha_grid:\n",
    "            for n_steps in n_steps_grid:\n",
    "                agent = ExpectedSarsa(\n",
    "                    width, \n",
    "                    height,\n",
    "                    n_actions = 2,\n",
    "                    alpha = alpha, \n",
    "                    epsilon = epsilon, \n",
    "                    gamma = gamma, \n",
    "                    n_steps = n_steps, \n",
    "                    debug = 0, \n",
    "                    verbose = 0,\n",
    "                    seed = SEED, \n",
    "                    consider_height = False\n",
    "                )\n",
    "                agents.append(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126\n"
     ]
    }
   ],
   "source": [
    "print(len(agents))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "for agent in tqdm(agents):\n",
    "    print(\"###############################################################\")\n",
    "    agent.train_n_episodes(env, N_EPISODES, patience = PATIENCE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16 (main, Jan 11 2023, 16:16:36) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
