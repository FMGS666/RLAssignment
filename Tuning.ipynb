{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import gymnasium as gym\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import text_flappy_bird_gym\n",
    "\n",
    "from plotting.plotting import plot_value_function\n",
    "from Agents1.TemporalDifferenceAgent import TemporalDifferenceAgent\n",
    "from Agents1.ExpectedSarsa import ExpectedSarsa\n",
    "\n",
    "from __future__ import annotations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining Environment to Train Agents with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = 15\n",
    "width = 20 \n",
    "pipe_gap = 4\n",
    "env = gym.make(\n",
    "    'TextFlappyBird-v0', \n",
    "    height = height, \n",
    "    width = width, \n",
    "    pipe_gap = pipe_gap\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining Search Grids for TemporalDifferenceAgent(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters to tune:\n",
    "\n",
    "* Epsilon\n",
    "* Gamma\n",
    "* Alpha\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TDAgent_maxScore49_w20_h15_nAct2_eps0.1_nSteps1_gamma1_alpha0.001\n",
    "\n",
    "\n",
    "epsilon_grid = [\n",
    "    1e-1,\n",
    "    1e-2, \n",
    "    1e-3,\n",
    "    2e-2,\n",
    "    2e-2, \n",
    "    2e-3, \n",
    "]\n",
    "gamma_grid = [\n",
    "    1, \n",
    "    75e-2, \n",
    "    5e-1,\n",
    "]\n",
    "alpha_grid = [\n",
    "    1, \n",
    "    5e-1, \n",
    "    1e-1, \n",
    "    5e-2, \n",
    "    1e-2, \n",
    "    5e-3, \n",
    "    1e-3\n",
    "]\n",
    "n_steps_grid = [\n",
    "    1\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining Number of Episodes for each search, Patience for the search and Random Seed  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATIENCE = int(1e+3)\n",
    "N_EPISODES = int(5e+5)\n",
    "SEED = 1024"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Constructing Grid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "agents = []\n",
    "for epsilon in epsilon_grid:\n",
    "    for gamma in gamma_grid:\n",
    "        for alpha in alpha_grid:\n",
    "            for n_steps in n_steps_grid:\n",
    "                agent = ExpectedSarsa(\n",
    "                    width, \n",
    "                    height,\n",
    "                    n_actions = 2,\n",
    "                    alpha = alpha, \n",
    "                    epsilon = epsilon, \n",
    "                    gamma = gamma, \n",
    "                    n_steps = n_steps, \n",
    "                    debug = 0, \n",
    "                    verbose = 0,\n",
    "                    seed = SEED, \n",
    "                    consider_height = False\n",
    "                )\n",
    "                agents.append(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126\n"
     ]
    }
   ],
   "source": [
    "print(len(agents))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/126 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###############################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 500000/500000 [11:52<00:00, 701.47it/s]\n",
      "  0%|                                                                                          | 0/126 [11:52<?, ?it/s]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '.\\\\ESHistory\\\\ExpectedSarsa_maxScore79_w20_h15_nAct2_eps0.1_nSteps1_gamma1_alpha1.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m agent \u001b[39min\u001b[39;00m tqdm(agents):\n\u001b[0;32m      3\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m###############################################################\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m     agent\u001b[39m.\u001b[39;49mtrain_n_episodes(env, N_EPISODES, patience \u001b[39m=\u001b[39;49m PATIENCE)\n",
      "File \u001b[1;32mc:\\Users\\lollo\\iCloudDrive\\Desktop\\DSBA\\M2_T2\\reinforcement\\FlappyBird\\Agents1\\ExpectedSarsa.py:270\u001b[0m, in \u001b[0;36mExpectedSarsa.train_n_episodes\u001b[1;34m(self, env, n_episodes, patience)\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain_n_episodes\u001b[39m(\n\u001b[0;32m    265\u001b[0m         \u001b[39mself\u001b[39m, \n\u001b[0;32m    266\u001b[0m         env: gym\u001b[39m.\u001b[39mEnv, \n\u001b[0;32m    267\u001b[0m         n_episodes: \u001b[39mint\u001b[39m,\n\u001b[0;32m    268\u001b[0m         patience: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m1e+6\u001b[39m\n\u001b[0;32m    269\u001b[0m     ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 270\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__train_n_episodes(env, n_episodes)\n",
      "File \u001b[1;32mc:\\Users\\lollo\\iCloudDrive\\Desktop\\DSBA\\M2_T2\\reinforcement\\FlappyBird\\Agents1\\ExpectedSarsa.py:261\u001b[0m, in \u001b[0;36mExpectedSarsa.__train_n_episodes\u001b[1;34m(self, env, n_episodes, patience, dump)\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_score \u001b[39mand\u001b[39;00m dump:\n\u001b[0;32m    260\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dump()\n\u001b[1;32m--> 261\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_save_history(episodes_lengths, episodes_scores)\n\u001b[0;32m    262\u001b[0m \u001b[39mreturn\u001b[39;00m (episodes_lengths, episodes_scores)\n",
      "File \u001b[1;32mc:\\Users\\lollo\\iCloudDrive\\Desktop\\DSBA\\M2_T2\\reinforcement\\FlappyBird\\Agents1\\Agent.py:231\u001b[0m, in \u001b[0;36mAgent._save_history\u001b[1;34m(self, episodes_lengths, episodes_scores, path_name)\u001b[0m\n\u001b[0;32m    226\u001b[0m file_name \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(path_name, description_string)\n\u001b[0;32m    227\u001b[0m dump_dictionary \u001b[39m=\u001b[39m {\n\u001b[0;32m    228\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mepisodes_lengths\u001b[39m\u001b[39m\"\u001b[39m: episodes_lengths, \n\u001b[0;32m    229\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mepisodes_scores\u001b[39m\u001b[39m\"\u001b[39m: episodes_scores\n\u001b[0;32m    230\u001b[0m }\n\u001b[1;32m--> 231\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(file_name, \u001b[39m\"\u001b[39;49m\u001b[39mw\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39mas\u001b[39;00m file_dump:\n\u001b[0;32m    232\u001b[0m     json\u001b[39m.\u001b[39mdump(dump_dictionary, file_dump)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '.\\\\ESHistory\\\\ExpectedSarsa_maxScore79_w20_h15_nAct2_eps0.1_nSteps1_gamma1_alpha1.json'"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "for agent in tqdm(agents):\n",
    "    print(\"###############################################################\")\n",
    "    agent.train_n_episodes(env, N_EPISODES, patience = PATIENCE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
